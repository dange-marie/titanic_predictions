# ğŸ›³ï¸ Titanic - Machine Learning from Disaster

This project explores the classic Titanic dataset on Kaggle to predict passenger survival using machine learning techniques.  
Itâ€™s designed to reinforce the fundamentals of preprocessing, feature engineering, modeling, and validation.

## ğŸ¯ Objective
Predict whether a passenger survived the Titanic disaster based on personal characteristics (class, sex, age, fare, etc.).

## ğŸ“Š Kaggle Score
- âœ… Public score: **0.76555**

## ğŸ§  Model Used
- Main model: **XGBoost Classifier**
- 5-fold cross-validation to avoid overfitting

## âš™ï¸ Engineered Features
- `Fare_log`: log transformation of the fare to reduce skew
- `Title`: extracted from the name (Mr, Miss, etc.)
- `Pont`: derived from cabin information
- One-hot encoding for `Embarked` categories
- Label encoding for `Sex`, `Ticket`, and others
- (Planned) `FamilySize` and `IsAlone` features

## ğŸ“‚ Files
- `src/titanic_model.ipynb`: full notebook including preprocessing, feature engineering, training, and submission
- `output/submission.csv`: final submission file
- `README.md`: this file

## ğŸ”§ How to Run
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/titanic-kaggle.git
   cd titanic-kaggle
Install dependencies:

bash
Copy
Edit
pip install -r requirements.txt
Launch the notebook:

Use Jupyter Notebook or VS Code to open and run titanic_model.ipynb

ğŸ“ˆ Next Steps
Add Optuna for hyperparameter tuning

Create FamilySize and IsAlone features

Try model stacking (XGBoost + Random Forest + Logistic Regression)

---

## ğŸ“¦ Basic `requirements.txt` (recommended)
Create this file in your project root:

```txt
numpy
pandas
scikit-learn
xgboost
matplotlib
seaborn
jupyter
Then run:

bash
Copy
Edit
pip install -r requirements.txt
```

ğŸ‘¤ Author
dange â€” Data scientist & computer science enthusiast

ğŸ“¬ [angelodsu22@gmail.com]
